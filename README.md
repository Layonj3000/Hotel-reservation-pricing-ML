# AvaliaÃ§Ã£o Sprint 4-5 -> Programa de Bolsas Compass UOL / AWS - ABRIL/2024

<p align="center">
 <a href="#-descriÃ§Ã£o">DescriÃ§Ã£o</a>  â€¢
 <a href="#-funcionalidades">Funcionalidades</a>  â€¢ 
 <a href="#-como-usar-a-aplicaÃ§Ã£o">Como usar</a>  â€¢ 
 <a href="#-desenvolvimento">Desenvolvimento</a>  â€¢ 
 <a href="#-execuÃ§Ã£o">ExecuÃ§Ã£o</a>  â€¢ 
  <a href="#-arquitetura-aws">Arquitetura AWS</a>  â€¢
 <a href="#-dificuldades">Dificuldades</a>  â€¢
 <a href="#-autores">Autores</a> 
</p>

## ğŸ“œ DescriÃ§Ã£o

Projeto tem como objetivo classificar reservas de hotel com base na faixa de preÃ§o por quarto utilizando AWS SageMaker para treinamento de modelo, AWS RDS para armazenamento de dados, e FastAPI para exposiÃ§Ã£o de uma API de prediÃ§Ã£o. O projeto Ã© containerizado utilizando Docker.

## âœ… Funcionalidades

Este projeto possui diversas funcionalidades importantes, que permitem a classificaÃ§Ã£o de reservas de hotel com base em faixas de preÃ§o por quarto, utilizando um modelo de machine learning treinado no AWS SageMaker. Aqui estÃ£o as principais funcionalidades:

**1. Carregamento e PreparaÃ§Ã£o dos Dados**

- Notebooks Jupyter: Utilizamos notebooks para carregar, explorar e preparar os dados. Isso inclui limpeza dos dados, criaÃ§Ã£o de novas features e armazenamento dos dados processados no AWS S3 e AWS RDS.
- InteraÃ§Ã£o com RDS: ConexÃ£o ao banco de dados relacional (RDS) da AWS para executar consultas SQL e manipular os dados diretamente.

**2. Treinamento do Modelo**

- AWS SageMaker: Utilizamos o AWS SageMaker para treinar um modelo de machine learning. O modelo Ã© treinado utilizando dados armazenados no S3 e a configuraÃ§Ã£o do treinamento Ã© feita nos notebooks.
- Modelo Random Forest: Escolha do algoritmo Random Forest devido Ã  sua robustez e alta performance em tarefas de classificaÃ§Ã£o.

**3. Desenvolvimento da API**

**FastAPI**
- Desenvolvemos uma API utilizando o framework FastAPI, que oferece uma interface RESTful para realizar prediÃ§Ãµes. A API Ã© configurada para carregar o modelo treinado a partir do S3.

**4. ContainerizaÃ§Ã£o**

- Docker: UtilizaÃ§Ã£o do Docker para containerizar a aplicaÃ§Ã£o, garantindo que o ambiente de execuÃ§Ã£o seja consistente em diferentes mÃ¡quinas.

**5. Deploy na AWS**
- EC2: A aplicaÃ§Ã£o pode ser implantada na AWS usando Amazon ECS, EKS ou instÃ¢ncias EC2. O uso de containers Docker facilita o deploy e a escalabilidade da aplicaÃ§Ã£o.
- AWS S3: O modelo treinado e os dados sÃ£o armazenados no Amazon S3, permitindo fÃ¡cil acesso e gerenciamento.

**Endpoint**
- /api/v1/predict: Endpoint POST que recebe um JSON com os dados da reserva e retorna a classificaÃ§Ã£o (faixa de preÃ§o).
- /: Endpoint GET que retorna uma mensagem de boas-vindas.


## ğŸ§‘â€ğŸ’» Como usar a AplicaÃ§Ã£o


## ğŸš€ Desenvolvimento
**ğŸ“‚ Estrutura de pastas**

 ```
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ Api
â”‚   â”‚   â”œâ”€â”€ Controllers                         
â”‚   â”‚   â”‚   â”œâ”€â”€ home_controller.py                # Controlador para a rota principal da API, respondendo com uma mensagem de boas-vindas.
â”‚   â”‚   â”‚   â””â”€â”€ prediction_controller.py          # Controlador para a rota de prediÃ§Ã£o, gerenciando a lÃ³gica de receber dados de entrada e retornar a prediÃ§Ã£o.
â”‚   â”‚   â”œâ”€â”€ Models
â”‚   â”‚   â”‚   â””â”€â”€ prediction_model.py               # Modelo de dados utilizado na API, definindo a estrutura dos dados de entrada para a prediÃ§Ã£o.
â”‚   â”‚   â”œâ”€â”€ Service                                
â”‚   â”‚   â”‚   â””â”€â”€ prediction_service                # ServiÃ§o para carregar o modelo treinado do S3 e realizar prediÃ§Ãµes.
â”‚   â”‚   â”œâ”€â”€ main.py                               # Ponto de entrada da aplicaÃ§Ã£o FastAPI
â”‚   â”‚   â”œâ”€â”€ requeriments.txt                      # Lista de dependÃªncias do Python.
â”‚   â”‚   â””â”€â”€ Dockerfile                            # ConfiguraÃ§Ã£o do Docker
â”‚   â”œâ”€â”€ Notebooks
â”‚   â”‚   â”œâ”€â”€ Treinamento                             
â”‚   â”‚   â”‚   â””â”€â”€ notebooks.ipynb                   # Notebooks Jupyter para desenvolvimento e treinamento dos dados
â”‚   â”‚   â”œâ”€â”€ AWS
â”‚   â”‚   â”‚   â””â”€â”€ rds.ipynb                         # Notebook para interaÃ§Ã£o com RDS, incluindo conexÃ£o ao banco de dados, execuÃ§Ã£o de consultas SQL e carregamento dos dados.
â”‚   â”‚   â””â”€â”€ requeriments.txt                      # Lista de dependÃªncias do Python.



 ```
**âš™ï¸ Tecnologias Utilizadas**
- Python: Linguagem de programaÃ§Ã£o principal.
- FastAPI: Framework para desenvolvimento da API.
- AWS SageMaker: ServiÃ§o da AWS para treinamento e deploy de modelos de machine learning.
- AWS S3: Armazenamento de dados e modelos.
- AWS RDS: Banco de dados relacional para armazenamento dos dados.
- Docker: Ferramenta de containerizaÃ§Ã£o.

## ğŸ’» ExecuÃ§Ã£o

**PrÃ©-requisitos** : 
- `Conta na AWS com permissÃµes para SageMaker, S3, e RDS`
- `Docker`
- `Python 3.9 ou superior`
- `Jupyter Notebook`


## ğŸŒ Arquitetura AWS
A arquitetura AWS deste projeto integra vÃ¡rios serviÃ§os da AWS para criar uma soluÃ§Ã£o de machine learning e prediÃ§Ã£o. A utilizaÃ§Ã£o de SageMaker, S3, RDS, FastAPI, Docker e EC2 permite que a aplicaÃ§Ã£o seja escalÃ¡vel, eficiente e fÃ¡cil de gerenciar. Cada componente foi escolhido para otimizar o desempenho e a escalabilidade, garantindo que o sistema possa lidar com grandes volumes de dados e fornecer prediÃ§Ãµes em tempo real.



## ğŸ” Dificuldades

- Tivemos uma dificuldade relacionada ao treinamento do sagemaker, encontramos um erro ao tentar ajustar o estimador em apenas uma das maquinas locais utilizadas e que gerou um bom tempo para o entedimento do mesmo e a descoberta para a soluÃ§Ã£o.


## ğŸ‘¤ Autores
- [Gabriel Venancio de Avelar](https://github.com/GabrielAvelarbr) | Email: 99gabrielavelar@gmail.com |
- [Layon Jose Pedrosa dos Reis](https://github.com/Layonj3000) | Email: layonjp300@gmail.com |
- [Leonardo Loureiro de Almeida](https://github.com/lloureiro2) | Email: leoloureiro44@gmail.com |

